{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOQmweZjlCpqm2rmlRHCxYu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Base Model**"],"metadata":{"id":"qKbwxwrWIMYH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVdxhTxxIIut"},"outputs":[],"source":["!mkdir sample_gen\n","!mkdir model"]},{"cell_type":"markdown","source":["## **Import Library**"],"metadata":{"id":"Mw6KWJQ5ISIC"}},{"cell_type":"code","source":["import numpy as np\n","from numpy.random import default_rng\n","import pandas as pd\n","import h5py\n","from matplotlib import pyplot as plt\n","\n","from keras.initializers import RandomNormal\n","from keras import Input\n","from keras.models import Model\n","from keras.layers import Dense\n","from keras.layers import Concatenate\n","from keras.layers import Conv2D, Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import Activation\n","from keras import activations\n","\n","# from keras.layers import Flatten\n","\n","from keras.optimizers import Adam\n","from keras.utils.vis_utils import plot_model\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n"],"metadata":{"id":"U25y0lcZIW9W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Set main parameters**"],"metadata":{"id":"oNqDjL7jIZLt"}},{"cell_type":"code","source":["# seed\n","np.random.seed(0) \n","\n","# for images\n","img_width = 256\n","img_height = 256\n","img_channels = 3\n","\n","# for Adam\n","learning_rate = 0.0002\n","beta_1 = 0.5\n","\n","img_shape = (img_width, img_height, img_channels)\n","\n","adam = Adam(learning_rate=learning_rate, beta_1=beta_1)"],"metadata":{"id":"Vq1zLcFuIeNs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Build Generator**"],"metadata":{"id":"R05yM7leIfWT"}},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"7Xv3UColIi_E"}},{"cell_type":"code","source":["def encoder(prev_layer, n_filters, n_kernels=4, n_strides=1, do_batchNorm=True):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","  \n","  encoder = Conv2D(n_filters, (n_kernels,n_kernels), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(prev_layer)\n","  if do_batchNorm == True:\n","    encoder = BatchNormalization()(encoder, training=True)\n","  encoder = LeakyReLU(alpha=0.2)(encoder)\n","\n","  return encoder"],"metadata":{"id":"34Z4wNQhIhrh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"wGxPlEnPIox_"}},{"cell_type":"code","source":["def decoder(prev_layer, skip_layer, n_filters, n_kernels=4, n_strides=1, do_dropout=True):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","\n","  decoder = Conv2DTranspose(n_filters, (n_kernels,n_kernels), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(prev_layer)\n","  decoder = BatchNormalization()(decoder, training=True)\n","  if do_dropout == True:\n","    decoder = Dropout(0.5)(decoder, training=True)\n","  decoder = Concatenate()([decoder, skip_layer])\n","  decoder = Activation(activations.relu)(decoder)\n","\n","  return decoder"],"metadata":{"id":"uDfxUBcSIqB_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generator"],"metadata":{"id":"9Fk5cMsLIsCP"}},{"cell_type":"code","source":["def build_generator(img_shape=img_shape, n_kernels=4, n_strides=1):\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","\n","  input_layer = Input(img_shape)\n","\n","  # encoders\n","  encoder_1 = encoder(input_layer, 64, n_kernels=n_kernels, n_strides=n_strides, do_batchNorm=False)\n","  encoder_2 = encoder(encoder_1, 128, n_kernels=n_kernels, n_strides=n_strides)\n","  encoder_3 = encoder(encoder_2, 256, n_kernels=n_kernels, n_strides=n_strides)\n","  encoder_4 = encoder(encoder_3, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  encoder_5 = encoder(encoder_4, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  encoder_6 = encoder(encoder_5, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  encoder_7 = encoder(encoder_6, 512, n_kernels=n_kernels, n_strides=n_strides)\n","\n","  bottleneck = Conv2D(512, (n_kernels, n_kernels), strides=(n_strides, n_strides), padding=\"same\", kernel_initializer=init)(encoder_7)\n","  bottleneck = Activation(activations.relu)(bottleneck)\n","\n","  # decoders\n","  decoder_1 = decoder(bottleneck, encoder_7, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  decoder_2 = decoder(decoder_1, encoder_6, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  decoder_3 = decoder(decoder_2, encoder_5, 512, n_kernels=n_kernels, n_strides=n_strides)\n","  decoder_4 = decoder(decoder_3, encoder_4, 512, n_kernels=n_kernels, n_strides=n_strides, do_dropout=False)\n","  decoder_5 = decoder(decoder_4, encoder_3, 256, n_kernels=n_kernels, n_strides=n_strides, do_dropout=False)\n","  decoder_6 = decoder(decoder_5, encoder_2, 128, n_kernels=n_kernels, n_strides=n_strides, do_dropout=False)\n","  decoder_7 = decoder(decoder_6, encoder_1, 64, n_kernels=n_kernels, n_strides=n_strides, do_dropout=False)\n","\n","  output_layer = Conv2DTranspose(3, (n_kernels, n_kernels), strides=(n_strides,n_strides), padding='same', kernel_initializer=init)(decoder_7)\n","  output_layer = Activation(activations.tanh)(output_layer)\n","\n","  model = Model(inputs=input_layer, outputs=output_layer, 'generator')\n","  return model\n"],"metadata":{"id":"zXv7IG-dIrd4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Build Discriminator**"],"metadata":{"id":"QPf9moeEIy2C"}},{"cell_type":"code","source":["def build_discriminator(img_shape=img_shape, n_kernel=4, n_strides=1):\n","\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","\n","  # src_input = Sequential()\n","  src_input = Input(shape=img_shape)\n","\n","  # target_input = Sequential()\n","  target_input = Input(shape=img_shape)\n","\n","  concat_input = Concatenate()([src_input, target_input])\n","\n","  layer = Conv2D(64, (n_kernel,n_kernel), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(concat_input)\n","  layer = LeakyReLU(alpha=0.2)(layer)\n","\n","  layer = Conv2D(128, (n_kernel,n_kernel), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(layer)\n","  layer = BatchNormalization()(layer)\n","  layer = LeakyReLU(alpha=0.2)(layer)\n","\n","  layer = Conv2D(256, (n_kernel,n_kernel), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(layer)\n","  layer = BatchNormalization()(layer)\n","  layer = LeakyReLU(alpha=0.2)(layer)\n","\n","  layer = Conv2D(512, (n_kernel,n_kernel), strides=(n_strides,n_strides), padding=\"same\", kernel_initializer=init)(layer)\n","  layer = BatchNormalization()(layer)\n","  layer = LeakyReLU(alpha=0.2)(layer)\n","  \n","  layer = Conv2D(512, (n_kernel,n_kernel), padding=\"same\", kernel_initializer=init)(layer)\n","  layer = BatchNormalization()(layer)\n","  layer = LeakyReLU(alpha=0.2)(layer)\n","\n","  layer = Conv2D(1, (n_kernel,n_kernel), padding=\"same\", kernel_initializer=init)(layer)\n","\n","  ## Flatten\n","  # layer = Flatten()(layer)\n","  ## Dropout\n","  # layer = Dropout(0.5)(layer)\n","\n","  out_layer = Activation(activations.sigmoid)(layer)\n","\n","  model = Model(inputs=[src_input, target_input], outputs=out_layer, name='discriminator')\n","  model.compile(loss='binary_crossentropy', optimizer=adam, loss_weights=[0.5], metrics=['accuracy'])\n","  return model\n"],"metadata":{"id":"MI7sGH8-I1Id"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Connecting generator and discriminator to build GAN**"],"metadata":{"id":"-w-iX7X9I3A8"}},{"cell_type":"code","source":["def build_gan(generator, discriminator, img_shape=img_shape):\n","  discriminator.trainable = False\n","\n","  input_layer = Input(shape=img_shape)\n","  \n","  generator_layer = generator(input_layer)\n","\n","  discriminator_layer = discriminator([input_layer, generator_layer])\n","\n","  model = Model(inputs=input_layer, outputs=[discriminator_layer, generator_layer], name='GAN')\n","  model.compile(loss=['binary_crossentropy', 'mae'], optimizer=adam, loss_weights=[1,100])\n","  return model\n"],"metadata":{"id":"pfF1CszoI65X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Save model architecture images**"],"metadata":{"id":"7RWfEs-TJCkC"}},{"cell_type":"code","source":["def save_model_architecture_image(model, name):\n","  plot_model(model, to_file=f\"{name}_architecture.png\", show_shapes=True, show_layer_names=True)\n","\n","generator = build_generator(n_strides=2)\n","discriminator = build_discriminator(n_strides=2)\n","gan = build_gan(generator, discriminator)\n","\n","save_model_architecture_image(generator, \"generator\")\n","save_model_architecture_image(discriminator, \"discriminator\")\n","save_model_architecture_image(gan, \"gan\")"],"metadata":{"id":"4eZQ47fxJHyd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Prepare before training**\n","\n","label\n","\n","1: real\n","\n","0: fake"],"metadata":{"id":"W97rORe0JJu4"}},{"cell_type":"markdown","source":["## **Prepare Data**"],"metadata":{"id":"OBAeqKpKJLYE"}},{"cell_type":"code","source":["# get data from h5 file\n","def load_data(file_name):\n","  with h5py.File(file_name, \"r+\") as file:\n","    images = np.array(file['/images']).astype('uint8')\n","    sketches = np.array(file['/sketches']).astype('uint8')\n","\n","    # convert to 3 channels\n","    sketches = np.stack((sketches,)*3, axis=-1)\n","    \n","    # (0,255) -> (-1,1)\n","    images = (images / 127.5) - 1\n","    sketches = (sketches / 127.5) - 1\n","\n","  return images, sketches\n","\n","# random pairs of images for a batch\n","def get_real_sample_images_data(images, sketches, n_samples, n_patches=1, seed=None):\n","  # random instance\n","  rnd = default_rng(seed=seed)\n","  rand_i = rnd.choice(images.shape[0], n_samples, replace=False)\n","  X_images, X_sketches = images[rand_i], sketches[rand_i]\n","\n","  # add label 1\n","  y = np.ones((n_samples, n_patches, n_patches, 1))\n","\n","  return X_images, X_sketches, y\n","\n","def generate_sample_fake_data(generator, samples, n_patches=1):\n","  # generate fake images\n","  X = generator.predict(samples)\n","\n","  # add label 0\n","  y = np.zeros((len(X), n_patches, n_patches, 1))\n","\n","  return X, y"],"metadata":{"id":"ijS0XNKVJK4q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Summarize**"],"metadata":{"id":"H6V386jsJQ1B"}},{"cell_type":"code","source":["def rescale(images):\n","  # (-1,1) -> (0,1) for matplotlib\n","  return (images + 1) / 2\n","\n","def summarize(iteration, generator, images, sketches, n_samples):\n","  # real\n","  X_images, X_sketches, _ = get_real_sample_images_data(images, sketches, n_samples, seed=42)\n","\n","  # generate fake images\n","  X_fake_images, _ = generate_sample_fake_data(generator, X_sketches)\n","  \n","  plt.figure(figsize=(20,12))\n","\n","  X_sketches = rescale(X_sketches)\n","  X_images = rescale(X_images)\n","  X_fake_images = rescale(X_fake_images)\n"," \n","  # same sample images\n","  for i in range(n_samples):\n","    sketches_ax = plt.subplot2grid((3,n_samples), (0,i))\n","    real_ax = plt.subplot2grid((3,n_samples), (1,i))\n","    gen_ax = plt.subplot2grid((3,n_samples), (2,i))\n","\n","    sketches_ax.set_xticks([])\n","    sketches_ax.set_yticks([])\n","    real_ax.set_xticks([])\n","    real_ax.set_yticks([])\n","    gen_ax.set_xticks([])\n","    gen_ax.set_yticks([])\n","\n","    if i == 0:\n","      sketches_ax.set_ylabel(\"Sketches\", fontsize=20)\n","      real_ax.set_ylabel(\"Real images\", fontsize=20)\n","      gen_ax.set_ylabel(\"Generated images\", fontsize=20)\n","\n","    sketches_ax.imshow(X_sketches[i])\n","    real_ax.imshow(X_images[i][...,::-1])\n","    gen_ax.imshow(X_fake_images[i][...,::-1])\n","\n","  plt.savefig(f\"/content/sample_gen/sample_{str(iteration+1).rjust(7,'0')}.png\")\n","\n","  generator.save(f\"/content/model/generator_{str(iteration+1).rjust(7,'0')}.h5\")\n"],"metadata":{"id":"c8mZ-KC4JUDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_history(list_d_loss1, list_d_loss2, list_g_loss, list_d_acc1, list_d_acc2):\n","  plt.subplot(311)\n","  plt.plot(list_g_loss, label=\"g_loss\")\n","  plt.xlabel(\"iteration\")\n","  plt.ylabel(\"loss\")\n","  plt.legend()\n","\n","  plt.subplot(312)\n","  plt.plot(list_d_loss1, label=\"d_loss1\")\n","  plt.plot(list_d_loss2, label=\"d_loss2\")\n","  plt.xlabel(\"iteration\")\n","  plt.ylabel(\"loss\")\n","  plt.legend()\n","  \n","  plt.subplot(313)\n","  plt.plot(list_d_acc1, label=\"d_acc1\")\n","  plt.plot(list_d_acc2, label=\"d_acc2\")\n","  plt.legend()"],"metadata":{"id":"ER4l_nB_JW4a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Train**\n","d_loss1: discriminator (real images)\n","\n","d_loss2: discriminator (generated images)\n","\n","g_loss: generator"],"metadata":{"id":"88I-Zfr9JX_9"}},{"cell_type":"code","source":["def training(generator, discriminator, gan, images, sketches, epochs=100, batches=1, data):\n","\n","  n_patches = discriminator.output_shape[1]\n","\n","  # number of batches per epoch\n","  batches_per_epoch = int(len(sketches) / batches) \n","  n_iterations = batches_per_epoch * epochs\n","\n","  list_d_loss1 = []\n","  list_d_loss2 = []\n","  list_g_loss = []\n","  list_d_acc1 = []\n","  list_d_acc2 = []\n","\n","  for i in range(n_iterations):\n","\n","    X_images, X_sketches, y_real = get_real_sample_images_data(images, sketches, batches, n_patches)\n","\n","    X_fake_images, y_fake = generate_sample_fake_data(generator, X_sketches, n_patches)\n","\n","    d_loss1, d_acc1 = discriminator.train_on_batch([X_sketches, X_images], y_real)\n","    d_loss2, d_acc2 = discriminator.train_on_batch([X_sketches, X_fake_images], y_fake)\n","    g_loss, _, _ = gan.train_on_batch(X_sketches, [y_real, X_images])\n","\n","    print(\">>> iteration %d, g_loss: %.3f d_loss1: %.3f d_loss2: %.3f d_acc1: %.3f d_acc2: %.3f\" % (i+1, g_loss, d_loss1, d_loss2, d_acc1, d_acc2))\n","\n","    list_d_loss1.append(d_loss1)\n","    list_d_loss2.append(d_loss2)\n","    list_g_loss.append(g_loss)\n","    list_d_acc1.append(d_acc1)\n","    list_d_acc2.append(d_acc2)\n","\n","\n","    if (i+1) % (batches_per_epoch * 10) == 0 or i in [0, 1]:\n","      summarize(i, generator, images, sketches, 5)\n","  \n","  plot_history(list_d_loss1, list_d_loss2, list_g_loss, list_d_acc1, list_d_acc2)\n","\n","  # save model\n","  # generator.save(f'/content/drive/MyDrive/trained_model/generator{data}.h5')"],"metadata":{"id":"sNgjLtSdJZD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images, sketches = load_data(\"/content/drive/MyDrive/data/test0_images.h5\")\n","generator = build_generator(n_strides=2)\n","discriminator = build_discriminator(n_strides=2)\n","gan = build_gan(generator, discriminator)\n","\n","training(generator, discriminator, gan, images, sketches, data=0)"],"metadata":{"id":"sbXmSb4KJbrA"},"execution_count":null,"outputs":[]}]}